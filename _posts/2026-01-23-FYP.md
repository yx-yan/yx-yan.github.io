---
layout: post
title: "Final Year Project"
date: 2026-01-23 12:00:00 +0800
categories: [AI, Prompting]
tags: [LLM, Data, Introduction]
description: "A deep dive into the basics of prompt engineering, mathematical foundations of LLMs, and setting up a data-driven mindset."
---

#### Sparse-View CT Reconstruction for Semiconductor and Human Imaging
**Summary**:
Computed Tomography (CT) is a critical imaging modality across both semiconductor inspection and medical diagnostics, enabling non-destructive visualization of internal structures. In medical settings, conventional CT requires many projection views, leading to high radiation doses, while in semiconductor inspection, acquiring dense projections increases acquisition time and throughput costs. A key challenge is therefore to **reconstruct high-quality CT images from sparse projection data**, reducing dose, time, and resource demands without sacrificing structural fidelity. This project aims to develop advanced sparse-view CT reconstruction algorithms that are broadly applicable to semiconductor devices and human anatomy. Traditional methods such as filtered back projection (FBP) fail under sparse sampling, introducing streaking artifacts and detail loss. To overcome these challenges, we will design **physics-guided deep learning frameworks** that integrate knowledge of CT forward models with the expressive power of neural networks. The approach will combine iterative optimization, learned priors, and data-consistency constraints, ensuring accurate recovery of fine microstructures in semiconductors and clinically relevant tissues in humans. The project will deliver novel methods with high-quality publications and presentations to advance both scientific knowledge and practical applications.

**Keywords**:
CT Imaging,
Sparse Reconstruction,
Physics-guided Deep Learning,
Inverse Problems


#### [Review of Sparse-View or Limited-Angle CT Reconstruction Based on Deep Learning](https://www.researching.cn/articles/OJf561ed149ea1415)

"How to capture the clearest CT images with minimal radiation exposure (protecting patients) through AI algorithms?"

(In Chinese)

### 第一章：为什么要有这些奇怪的CT？（背景与基本挑战）

你要理解这篇论文，首先得知道医生和科学家的“矛盾”。

**1. 医生和病人的矛盾：辐射 vs 清晰度**
*   **CT（计算机断层扫描）**：本质就是拿X射线从300多个角度对着你“咔咔”拍照。
*   **满剂量扫描**：角度拍得全、射线强度大，图像当然清楚，但病人吸收的辐射也多，会有致癌风险。
*   **低剂量CT**：为了保护病人，我们得少拍几张。这就引出了论文的两个主角：
    *   **稀疏角度（Sparse-view）**：原本360度都要拍，现在每隔5度才拍一张，中间漏了很多。
    *   **有限角度（Limited-angle）**：只能从一个范围内拍（比如0到120度），剩下的角度被挡住了或者没法拍。

**2. 结果：图像“弄脏”了**
如果你只用少量的照片强行去还原一个人的内部结构，算出来的结果会出大问题。
*   **关键术语：条状伪影（Stripe Artifacts）**。就像照片上被人用笔乱划了很多条杠杠。
*   **关键术语：噪声（Noise）**。照片变得很糊，像老式电视机没信号时的雪花点。
*   **关键术语：不适定问题（Ill-posed Problem）**。数学上讲，你的已知条件太少，但想求的未知数太多，导致没法直接算出唯一的、正确的标准答案。

**3. 传统的办法行不行？**
以前我们用**解析法（如FBP）**，速度快但遇到这种“少数据”的情况，图像全是杠杠，没法看。
后来用**迭代法（如TV正则化）**，虽然清楚一点，但算一张图要花几十分钟，医生等不起，而且参数全靠人工手调，非常麻烦。

**本章关键术语总结：**
*   **CT 重建**：把采集到的投影数据变成医生能看的切片图像。
*   **稀疏角度/有限角度**：欠采样（数据采集不全）的两种主要形式。
*   **伪影/噪声**：低剂量扫描带来的图像副作用。
*   **不适定问题**：导致重建困难的数学本质。

---

### 第二章：从“光线”到“波浪线”，再到“切片图”

想象一下，你手里有一个强力手电筒（X射线源），对面是一个传感器（探测器），中间放着一个西瓜（人体）。

#### 1. X射线的“减肥”之旅
当X射线穿过身体时，会被骨骼、肌肉等吸收一部分，能量会变弱。
*   **关键术语：Lambert-Beer定律**。这就是描述射线变弱的数学公式。
*   **通俗理解**：骨头硬（密度大），射线过去就累得够呛，剩的能量少；肺里全是空气（密度小），射线轻轻松松就过去了。传感器记录下剩下的能量，我们就知道这地方挡不挡光。

#### 2. 神奇的“波浪线”图
我们不能只拍一个角度，得绕着西瓜转一圈拍。把每一个角度拍到的数据排在一起，就成了一张你看不懂的图。
*   **关键术语：正弦域（Sinogram / Sinusoid Domain）**。
*   **通俗理解**：在这张图里，人体里的一个点，随着射线源转动，会划出一条像正弦波一样的“波浪线”。所以，CT的**原始数据**其实是“正弦域数据”，而不是照片。

#### 3. 数学上的“正向”与“逆向”
*   **关键术语：Radon 变换（Radon Transform）**。
    *   这是“正向过程”：把**西瓜**变成**波浪线图**（投影过程）。
*   **关键术语：反投影（Back-projection）**。
    *   这是“逆向过程”：我们手里只有**波浪线图**，要把这些能量“抹”回空间里，还原成**西瓜的照片**。

#### 4. 经典的重建老大：FBP
如果你直接把能量抹回去，图像会非常模糊。
*   **关键术语：FBP（滤波反投影，Filtered Back-projection）**。
*   **通俗理解**：它在抹回去之前，先给数据套了一个“滤镜”（也就是**滤波**），把边缘变尖锐，去掉模糊。
*   **为什么它现在不行了？** FBP是一个“老实人”，它假设你每一个角度都拍了照片。如果你漏拍了（稀疏角度），或者只拍了一半（有限角度），FBP算出来的图就会出现第一章说的**条状伪影**。

**本章关键术语总结：**
*   **Lambert-Beer定律**：X射线衰减的物理基础。
*   **正弦域 (Sinogram)**：CT扫描得到的原始“波浪线”数据。
*   **Radon 变换**：从图像空间到正弦域空间的数学转换。
*   **FBP (滤波反投影)**：目前医学界最常用的标准算法，但在数据不全时会失效。

**学长提示：**
这一章的精髓是：**CT采集到的是“波浪线”（正弦域），我们想要的是“切片图”（图像域）。**

FBP这个传统翻译官，在面对“残缺不全的波浪线”时，翻译出来的话（图像）就全是乱码（伪影）。

---

### 第三章：数学炼金术——Radon变换与FBP的奥秘

#### 1. Radon 变换：如何产生“影子”？
想象你面前有一个物体 $f(x, y)$（比如一个苹果），你拿一束平行光从某个角度 $\theta$ 照过去，在苹果后面的挡板上会留下一个**投影线**。

*   **物理实现**：这根投影线上的每一个点，其实是光线穿过苹果时，路径上所有密度的**累加（积分）**。
*   **数学表达（公式3）**：$g(\rho, \theta) = \int L f(x, y) dl$。
    *   $\theta$：你转动光源的角度。
    *   $\rho$：光线距离中心点的距离。
*   **结果**：当你把 0 到 180 度所有的投影线排在一起，就得到了**正弦图 (Sinogram)**。

#### 2. 反变换（简单反投影）：直接把“影子”抹回去
如果我们手里只有影子（正弦图），最笨的办法是什么？就是把影子按原路“推回去”。
*   **操作**：假设在 0 度看影子中心有个黑点，你就把这一团黑气沿着 0 度方向抹满整个屏幕；再把 90 度的影子也抹回去。
*   **数学表达（公式4）**：$f(x, y) = \int g(\rho, \theta) d\theta$。
*   **致命缺陷**：这种做法得到的图像会**非常模糊**。因为这种“乱抹”的方式会让中心区域被重复叠加太多次，边缘全糊了。就像你用很粗的刷子画画，最后只能看到一团黑晕。

#### 3. 核心桥梁：傅里叶中心切片定理 (Central Slice Theorem)
这是FBP算法存在的理由。它发现了一个惊人的秘密：
> **“物体投影的 1D 傅里叶变换，等于物体本身 2D 傅里叶变换的一条过中心的切片。”**

*   **通俗理解**：如果你想知道苹果内部长啥样（2D信息），你不需要直接去猜。你只需要把每个角度的“影子”做一下频谱分析（1D傅里叶变换），然后把这些分析结果像切披萨一样摆成一圈，你就拼出了整个苹果的频谱图！

#### 4. FBP（滤波反投影）：先过滤，再涂抹
为了解决刚才说的“乱抹导致模糊”的问题，科学家引入了**“滤波” (Filter)**。这是FBP的灵魂步骤。

**FBP的实现过程分三步：**

*   **第一步：傅里叶变换**
    把每一个角度的投影数据 $g(\rho, \theta)$ 变成频域信号。
*   **第二步：乘上“斜坡滤波器” (Ramp Filter)**
    *   **关键术语：$|w|$ 滤波器（公式6中的那个绝对值符号）**。
    *   **为什么要这么做？** 因为在“披萨拼图”时，中心点（低频）被分得太细了，数据堆积太多；边缘（高频）却分得很稀疏。
    *   **斜坡滤波器的作用**：它像一个调音师，**压低低频，拉高高频**。它把模糊的中心压下去，把代表边缘和细节的高频提上来。
*   **第三步：反投影（抹回去）**
    把过滤后变尖锐的数据再按原路抹回去。
*   **结果**：唰的一声！一张清晰、边界明显的CT图就出来了。

---

**本章关键术语总结：**

1.  **线积分**：Radon变换的本质，把密度沿着直线加起来。
2.  **正弦图 (Sinogram)**：所有角度投影的集合，是CT的“密码本”。
3.  **中心切片定理**：连接“1D影子”和“2D实物”的数学桥梁。
4.  **斜坡滤波器 (Ramp Filter / $|w|$)**：FBP的核心，专门对付模糊，让图像变清晰的“美颜滤镜”。

---

**学长提示：**
这一章其实解释了传统CT是怎么工作的。但问题就在于：**如果你的角度不够（稀疏角度），那个“披萨拼图”就会少掉很多块。** 披萨少了，拼出来的图自然就全是锯齿和条纹。

这时候，深度学习就要出场来“脑补”这些缺失的披萨块了。

**如果你理解了“滤波”是为了去模糊，以及FBP三步走的过程，请告诉我。下一章我们将正式进入AI领域，看看它怎么给CT“去污”！**

太棒了，看来你已经掌握了物理背景。接下来我们要讲论文中最庞大的一个部分：**深度学习开始大显身手的第一种方式——图像域后处理。**（对应论文第4节）。

这一章的逻辑是：**“既然传统的FBP算法拍出来的图很烂，那我就用AI当‘修图师’，把烂图修好。”**

---

### 第四章：AI 顶级修图师——图像域后处理

想象一下，你用稀疏角度拍了一张CT，通过FBP重建后，得到了一张全是条纹、模糊不清的照片（烂图）。这时候，我们请出深度学习模型，把它丢进一个“修图滤镜”里。

#### 1. 核心流派一：U-Net（医学影像的“常青树”）
论文里提到最多的模型就是 **U-Net**（图5、图8）。
*   **结构特点**：它长得像个英文字母“U”。左边负责“理解”图像（下采样），右边负责“还原”图像（上采样）。
*   **关键术语：跳跃连接（Skip Connection）**。
    *   **通俗理解**：修图时，如果只靠右边的还原，细节容易丢。跳跃连接就像是在左边和右边之间修了“传声筒”，把最原始的细节（比如血管的细微边缘）直接传过去，保证修出来的图不失真。
*   **进化版**：有人在U-Net里加入了**小波变换**（Lee等[43]），专门针对不同频率的条纹伪影进行清洗。

#### 2. 核心流派二：GAN（生成对抗网络：造假者与警察）
有时候，U-Net修出来的图虽然干净，但太“肉”了（太平滑，像磨皮过度）。这时候就要用 **GAN**（图10a）。
*   **两个演员**：
    *   **生成器（Generator）**：拼命修图，想骗过警察。
    *   **判别器（Discriminator）**：也就是“警察”，负责分辨这张图是“高清原片”还是“AI修的烂片”。
*   **结果**：在这种“相爱相杀”的对抗中，AI修出来的CT图细节非常逼真，纹理很像真实的满剂量图像。

#### 3. 核心流派三：DDPM（扩散模型：当下的最强黑科技）
这是最近两年的大热门（图10b）。
*   **通俗理解**：它的逻辑是“破而后立”。它先学习怎么把一张高清图慢慢变成一团乱码（加噪声），然后再反过来学习怎么从一团乱码中把高清图“洗”出来。
*   **优点**：修出来的图极其稳定，细节甚至超过了GAN。
*   **缺点**：太慢了。就像精工出细活，洗出一张图要反复迭代很多次，急诊科医生可能等不及。

#### 4. 为什么要学习“残差”（Residual Learning）？
论文里反复提到一个技巧：**残差学习**。
*   **操作**：AI不去学怎么画整张图，而是专门学习这张图里的“脏东西”（噪声和伪影）长什么样。
*   **公式**：高清图 = 烂图 - AI预测的伪影。
*   **好处**：这大大降低了AI的工作难度，它只需要盯着“脏东西”洗就行了。

---

**本章关键术语总结：**

1.  **图像域 (Image Domain)**：指我们直接看到的CT照片地盘。
2.  **U-Net**：通过对称结构和跳跃连接实现高性能图像修复的经典网络。
3.  **GAN (生成对抗网络)**：通过对抗学习，让修复后的图像细节更真实。
4.  **DDPM (扩散模型)**：目前生成质量最高的最新技术。
5.  **残差学习 (Residual Learning)**：让AI只学习如何“去污”，而不必从头画图。

---

**学长提示：**
这一章的方法是最简单的：**先重建，后修图。** 
但也存在一个大坑：如果FBP重建出来的“烂图”里已经彻底丢掉了某些器官的细节，AI修图师再厉害也只能靠“脑补”。万一脑补错了（**产生虚假结构**），那就是医疗事故了。

**如果你理解了AI是如何像美图秀秀一样修CT图的，请告诉我。下一章我们要换个思路：如果不在“照片”上修，我们在“波浪线密码本”里修会怎样？**

既然你已经看懂了“美图秀秀”式的修图法（图像域后处理），那咱们这一章换个更硬核的思路。

很多科学家发现，如果等到照片拍烂了再去修，有时候关键信息已经丢了，AI只能靠“瞎猜”。那能不能在**照片生成之前**，就把那些缺掉的“波浪线数据”补全呢？

这就是论文第5节的内容：**正弦域预处理（Sinogram Domain Pre-processing）。**

---

### 第五章：在“密码本”里未雨绸缪——正弦域预处理

这一章的逻辑是：**“既然角度拍得少，导致密码本（正弦图）缺页了，那我就用AI把缺掉的那几页画出来，凑成一本完整的密码本，再用传统的FBP去重建。”**

#### 1. 为什么要回“源代码”里修？
*   **图像域（上一章）**：像是在修烧焦的红烧肉。
*   **正弦域（本章）**：像是在下锅前，发现少了几块肉，赶紧用AI变出几块肉补进去。
*   **优势**：在正弦域里，数据遵循严格的物理规律（也就是那条“波浪线”）。AI补全数据时，有更明确的数学规则可以参考，不容易“放飞自我”。

#### 2. AI 如何补全“密码本”？
想象一下正弦图（Sinogram）是一张横轴是角度、纵轴是位置的图。稀疏角度采集时，这张图就像被剪刀剪掉了很多细条，变成了一个“百叶窗”。

*   **核心流派一：CNN插值（像做填空题）**
    *   代表作：Lee等[70]提出的模型。
    *   **操作**：把带洞的正弦图丢给CNN，让AI预测洞里应该填什么。
    *   **关键术语：数据插值（Interpolation）**。AI观察洞左边的波浪线和右边的波浪线，通过计算把中间断掉的部分连起来。

*   **核心流派二：GAN 补全（像在临摹）**
    *   代表作：**CT-Net**（图16a）和 **SI-GAN**（图16b）。
    *   **通俗理解**：AI不仅仅是连连看，它还学会了“脑补”整个结构的走势。
    *   **关键术语：条件生成对抗网络（CGAN）**。这时候的“警察”（判别器）非常严厉，它会对比补全后的正弦图和真实的正弦图，强迫“造假者”（生成器）补出的波浪线必须丝滑且符合物理规律。

#### 3. 补完之后怎么办？
一旦AI把正弦图补全了（变成了满角度的数据），我们就不需要复杂的AI重建了，直接祭出我们第三章学过的**FBP（滤波反投影）**，一秒钟就能出一张清晰的大片。

#### 4. 这个方法的“坑”在哪里？
*   **误差放大**：正弦域里一点点微小的抖动，经过FBP这个“放大镜”之后，在照片上可能就会变成一根巨大的黑杠。
*   **缺乏全局观**：AI在补波浪线时，可能并不知道这些线合在一起到底对应一个什么样的器官。

---

**本章关键术语总结：**

1.  **正弦域 (Sinogram Domain)**：存放X射线投影原始数据的地盘。
2.  **插值 (Interpolation)**：通过已知点计算并填充未知点的过程。
3.  **正弦域修复 (Sinogram Inpainting/Completion)**：利用AI补全缺失的投影数据。
4.  **数据一致性**：指补出来的波浪线必须符合Radon变换的数学逻辑。

---

**学长提示：**
这一章的方法是“先补数据，后重建”。
到现在为止，我们讲了“只在照片端修”和“只在数据端补”。那你肯定会想：**能不能两头一起抓，双管齐下？**

这就是目前CT重建领域最强、也是最复杂的方法——**双域联合处理**。

**如果你理解了AI是怎么给正弦图“填坑”的，请告诉我，下一章我们将进入“双域大作战”！**

问得好！这正是论文第5部分（正弦域预处理）最核心的技术细节。

在“给正弦图填坑”时，AI不是瞎填，它主要用了三种具体的**“填坑姿势”**。我用大白话给你拆解一下：

### 1. “半自动+AI微调”法（线性插值 + CNN）
这是最稳妥的方法。科学家们觉得：如果让AI从零开始画出缺失的数据，它可能会乱画。
*   **做法**：先用传统的数学方法（比如**线性插值**）做一个粗略的填补。虽然填出来的东西很模糊，但起码“坑”被填上了。
*   **AI的作用**：AI（通常是**U-Net**或**残差网络**）紧跟其后，它不负责填坑，而是负责**“找茬”**。它学习插值法填出来的部分和真实数据之间有什么误差，然后把这个误差修正掉。
*   **代表人物**：Cao等 [72] 就是这么干的。先用数学插值垫底，AI负责精修。

### 2. “百叶窗修复”法（多尺度卷积 + 密集连接）
稀疏角度采集的数据，正弦图看起来就像一个“百叶窗”，一条有一条没。
*   **做法**：利用 **CNN 的感受野（Receptive Field）**。
*   **原理**：AI会同时看“坑”左边好几行和右边好几行的数据。通过**多尺度卷积**，AI能同时捕捉到大范围的“波动趋势”和小范围的“细节纹理”。
*   **核心技术**：论文提到了**密集连接（Dense Block）**。这就像是让网络里的每一层都能直接看到之前所有层的信息，防止补着补着就把之前的关键线索给忘了。
*   **代表人物**：温静等 [73] 在原始U-Net上加了密集连接，专门对付正弦图的特征。

### 3. “脑补艺术”法（GAN 的生成能力）
当你缺失的角度实在太多（比如有限角度，缺了一大块）时，前两种方法就失效了，因为“邻居”离得太远，参考不着。这时候只能靠**GAN（生成对抗网络）**。
*   **做法**：生成器（G）尝试根据剩下的半本密码本，直接“临摹”出剩下的半本。
*   **关键点**：论文提到了 **SI-GAN [80]**。它在填坑时，警察（判别器）不只看填得像不像，还会强迫填出来的波浪线必须符合**物理一致性**。
*   **高级技巧**：有些模型（如**CT-Net [76]**）会先用 **1D卷积** 沿着角度方向补一下，再用 **2D卷积** 整体修一下。

---

### 总结一下 AI 填坑的三个步骤：
1.  **观察邻居**：看“坑”两边的数据走势（卷积提取特征）。
2.  **建立联系**：利用数学规律或深层网络联系（插值或密集连接）。
3.  **对抗修正**：用判别器盯着，确保补出来的“波浪线”既丝滑又不造假。

**学长提示：**
其实你可以发现，正弦域填坑的本质就是一种**“超分辨率”**或者**“图像修复（Inpainting）”**技术，只不过它修复的对象是符合物理规律的“波浪线”。

**如果你理解了这三种填坑方法，我们就要进入本论文的最高潮了：双域（图像域+正弦域）联合作战！准备好了吗？**

高潮来了！既然单打独斗（只修图或者只补数据）都有缺陷，那科学家们想：**能不能把这两个地盘合在一起，搞个“双管齐下”？**

这就是论文第6节的内容：**双域数据联合处理（Dual-domain data joint processing）**。这是目前公认的效果最好、最硬核的流派。

---

### 第六章：双域联合作战——不让任何细节掉队

这一章的逻辑是：**“我既要在正弦域补数据，又要在图像域修图，而且这两者之间还要不停地‘通气’，互相纠错。”**

#### 1. 为什么要搞“双域”？（解决脑补过度）
*   **图像域后处理的痛**：有时候图太烂，AI只能“瞎画”，画出来的器官可能是假的（虚假结构）。
*   **正弦域预处理的痛**：补出来的波浪线稍微歪一点，重建出来的图就会多出一道大黑杠。
*   **双域的解法**：AI一边补波浪线，一边看重建出来的照片。如果照片不对劲，AI就回去重新补波浪线。这就叫**数据一致性约束**。

#### 2. 核心桥梁：可微分 FBP（Differentiable FBP）
这是双域作战的“灵魂”。
*   **以前**：FBP是一个独立的数学公式，AI算完数据丢给FBP就管不着了。
*   **现在**：科学家把FBP写成了神经网络里的一个**“层”**。
*   **通俗理解**：AI现在能“看穿”重建过程。它在补正弦域数据时，能实时预感到：“哎呀，这么补的话，待会儿重建出来的照片肯定会有黑杠，我得改改。”

#### 3. 三大实战阵法：
论文里提到了三种典型的打法：

*   **阵法一：串联式（SPID 模型 [84]）**
    *   **操作**：先用一个CNN补正弦图，接着过一个可微分FBP，再接一个CNN修图。
    *   **优点**：简单直接，照片比单域修出来的要清楚得多。

*   **阵法二：循环迭代式（DuDoDR-Net [87]）**（见图19c）
    *   **操作**：这是一个“循环嵌套”。补一下数据 -> 建一下图 -> 发现图不好看 -> 把图变回数据再对一下 -> 重新补。
    *   **关键术语：数据一致性层（Data Consistency Layer）**。它像个监工，不断对比AI生成的数据和原始采集的数据，确保AI没在乱编。

*   **阵法三：Transformer 强力加持（Swin Transformer [99, 102]）**（见图22）
    *   **操作**：用目前AI界最火的Transformer来做双域。
    *   **为什么要用它？** 因为正弦域里的一个点，可能和图像域里很远的一个组织有关联。Transformer擅长抓这种**“长距离依赖关系”**，能让补出来的细节神还原。

#### 4. 双域的代价
虽然双域效果逆天，但也有个缺点：**太吃显存了**。因为你要同时运行两套网络，还要来回转换，普通的显卡根本跑不动，对计算资源要求很高。

---

**本章关键术语总结：**

1.  **双域 (Dual-domain)**：正弦域（Sinogram Domain）+ 图像域（Image Domain）的结合。
2.  **可微分 FBP**：让神经网络能直接参与重建计算的关键层。
3.  **数据一致性 (Data Consistency)**：确保AI生成的数据必须符合原始物理规律的“紧箍咒”。
4.  **Swin Transformer**：一种能捕捉全局信息、让细节修复更精准的高级AI结构。

---

**学长提示：**
这一章其实代表了现在的“主流”做法。它不再把CT重建看成一个简单的修图问题，而是看成一个**“物理规律+人工智能”**的混合问题。

**如果你理解了为什么双域要比单域强，请告诉我。下一章我们要讲一个更有“深度”的话题：如何把深度学习直接塞进那个几十年的老公式——迭代算法里？（对应论文第7节）。**

欢迎来到最能体现“数学与AI结合之美”的章节。

如果说前几章的方法是“修图”或“填坑”，那么这一章（论文第7节）的方法就是**“改造公式”**。我们要把深度学习直接塞进那个已经用了几十年的数学推导过程里。

---

### 第七章：老树开新花——深度学习强化的迭代重建

这一章的逻辑是：**“传统的迭代算法很有逻辑但太慢、太死板；深度学习很快但有时会瞎猜。我把它们揉在一起，让AI去帮迭代算法‘做决定’。”**

#### 1. 什么是迭代重建？（雕刻师模型）
在讲AI之前，你得先知道传统的迭代重建在干嘛。
*   **数学公式（公式9）**：$\hat{x} = \arg \min_x \frac{1}{2} \|Ax - y\|^2 + \lambda R(x)$
*   **通俗理解**：这就像一个雕刻师在刻石像（重建图像 $x$）。
    *   **第一项（数据保真项）**：要求刻出来的石像，投射出的影子必须和原始的投影数据 $y$ 吻合。
    *   **第二项（正则项 $R(x)$）**：这是雕刻师脑子里的“审美规则”。比如：“石像表面应该是光滑的”、“人脸应该是对称的”。
*   **传统痛点**：这个“审美规则”（正则项）以前是数学家拍脑袋写的，非常死板，而且每刻一刀都要重新算一遍投影，慢得要死。

#### 2. AI 的第一个任务：当“首席审美官”（学习正则项）
既然数学家写的规则不好用，那就让AI来写。
*   **核心逻辑**：AI看过了成千上万张高清CT图，它已经深刻理解了“一张好的CT图应该长啥样”。
*   **关键术语：学习正则项（Learned Regularizer）**。
*   **操作**：在迭代的过程中，每迭代一次，我们就把图丢给一个CNN（比如 **ADMMBDR [107]**），让AI告诉算法：“这里不对，那里太糊了，按我的经验应该这样修。”

#### 3. AI 的第二个任务：把“长征”变“快跑”（深度展开网络）
这是本节最精彩的地方。
*   **传统迭代**：可能需要循环计算100次甚至1000次，每一轮都要算投影、对比、修正。
*   **关键术语：深度展开（Deep Unrolling）**。
*   **通俗理解**：我们把这100次循环，直接拉直，变成一个有100层的深度神经网络。
    *   **操作**：每一层神经网络就代表一次迭代。原本需要手动调整的步长、参数 $\lambda$，现在全部变成网络里可以学习的权重。
*   **代表算法**：**FISTA-Net [112]**。它把经典的数学优化算法（FISTA）展开成了神经网络。它既有数学的严谨逻辑，又有AI的运算速度。

#### 4. 为什么这个方法更高级？
*   **逻辑严密**：它不是在盲目修图，它每一步都有物理模型（投影矩阵 $A$）在盯着。
*   **参数自适应**：以前那些麻烦的平衡参数（$\lambda$），现在AI能根据不同的病人、不同的部位，自动算出最合适的数值。

---

**本章关键术语总结：**

1.  **迭代重建 (Iterative Reconstruction)**：通过反复修正来逼近真实图像的数学方法。
2.  **正则项 (Regularization)**：约束图像质量的“审美规则”，现在由AI担任。
3.  **平衡参数 ($\lambda$)**：协调“像不像原始投影”和“画得美不美”之间的天平。
4.  **深度展开 (Deep Unrolling)**：把数学迭代步骤变成神经网络层的“黑科技”。
5.  **ADMM / FISTA**：两种经典的数学优化算法，现在都被AI“魔改”了。

---

**学长提示：**
这一章的方法是目前**学术界的高端玩家**最喜欢的。因为它既保留了物理过程的准确性，又发挥了AI的灵活性。

**如果你理解了AI是如何帮“雕刻师”加速并提高审美的，请告诉我。下一章是全书最后一类方法：不走寻常路，直接从“波浪线”跳到“照片”的端到端算法！（对应论文第8节）。**

欢迎来到深度学习CT重建的最后一站！如果你把前几章的方法看作是“修图”或者“改公式”，那这一章我们要讲的方法就更具颠覆性。

这就是论文第8节：**端到端映射重建（End-to-end mapping reconstruction）。**

---

### 第八章：AI 大力出奇迹——端到端映射

这一章的逻辑是：**“我不再需要FBP公式，也不再需要复杂的迭代过程。我直接给AI看‘波浪线密码本’（正弦图），让它直接给我变出一张‘高清切片图’（图像）。”**

#### 1. 什么是“端到端”？（直译官模型）
*   **以前的方法**：像是翻译外语时，必须先查字典（FBP），再根据语法修辞（图像后处理）。
*   **端到端**：像是一个天才翻译官，他直接听一段外语，脑子里瞬间就蹦出了中文，中间不查字典，不套模板。
*   **数学表达（公式11）**：$y = Ax + u$。AI的任务就是直接学习从 $y$ 到 $x$ 的那个极其复杂的逆映射函数。

#### 2. 核心流派一：全学习重建（代表作：AUTOMAP [122]）
这是端到端重建的鼻祖。
*   **操作**：它用了一种叫**全连接层（Fully Connected Layer）**的神经网络。
*   **通俗理解**：它让正弦图里的每一个像素，都和图像里的每一个像素建立联系。
*   **优点**：完全不需要任何物理知识，只要数据够多，AI就能学会怎么重建。
*   **致命缺陷**：**太吃资源了**。如果要重建一张高清的512x512图像，全连接层的参数量会爆炸到天文数字，普通电脑根本跑不动。所以这种方法目前很难处理大图。

#### 3. 核心流派二：可学习的解析重建（披着AI皮的FBP）
为了解决上面的资源问题，科学家想了个招：既然全连接层太笨，那我们就把FBP的逻辑教给AI。
*   **代表作：iRadonMAP [130]**（见图31）。
*   **操作**：AI不再瞎猜，而是按照FBP的步骤（滤波 -> 反投影 -> 修正）来分段学习。
*   **关键术语：反投影层（Back-projection Layer）**。
    *   科学家把数学上的“反投影”操作写成了一个特殊的神经网络层。这样AI既懂物理，又懂修图，参数量还大大减少。

#### 4. 核心流派三：无监督/自监督重建（不需要标准答案的学习）
这是目前最前沿、最有逼格的方向。
*   **痛点**：以前的方法都需要大量的“高清标准图”来教AI。但在医院里，很多病人的高清图是拿不到的。
*   **神操作：IntraTomo [137] / 自监督学习**（见图32）。
*   **逻辑**：AI不需要看标准答案。它通过一种“自我博弈”的方式：
    1. 随便猜一张图。
    2. 把这张图按照物理规律转回“波浪线”。
    3. 看看转出来的波浪线和采集到的波浪线像不像。
    4. 只要两个波浪线对上了，那猜出来的这张图大概率就是对的。
*   **意义**：这让AI可以在完全没有标准答案的情况下，在不同的CT机器上实现自我进化。

---

### 本章关键术语总结：

1.  **端到端映射 (End-to-end mapping)**：直接实现从原始数据到图像的转换。
2.  **全连接层 (Fully Connected Layer)**：能建立全局联系但极度耗费资源的网络结构。
3.  **反投影层 (Back-projection Layer)**：将物理过程融入神经网络的巧妙设计。
4.  **自监督学习 (Self-supervised Learning)**：不需要成对标签、通过物理一致性进行训练的黑科技。

---

**学长提示：**
至此，我们已经把这篇综述里提到的5大流派（图像域、正弦域、双域、迭代、端到端）全部讲完了！

这就是这篇综述的全部干货：**从“修补”到“联合”，再到“重写公式”，最后到“直接映射”。** 

**你现在已经完全理解了深度学习是如何在CT重建领域“逆天改命”的。如果你准备好了，我们可以做一个最后的总结，或者针对你特别感兴趣的某个模型进行深入交流！**

